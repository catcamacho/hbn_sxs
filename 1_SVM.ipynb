{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c048fd9-5a54-4d69-86b2-af07d261b3dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d880eca9-cba5-459e-b126-4c37f426b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import scipy.stats as scp\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, GroupKFold, permutation_test_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set(context='paper', style='white', font='Arial')\n",
    "\n",
    "today = date.today().strftime('%Y%m%d')\n",
    "\n",
    "project_dir = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/'\n",
    "data_dir = project_dir + 'proc/group/parcel_timeseries/sub_ts/'\n",
    "clin_dir = project_dir + 'proc/clin/'\n",
    "\n",
    "sample_file = project_dir + 'proc/group/datasets_info/sample_gord.32k_fs_LR.pscalar.nii'\n",
    "atlas_file = project_dir + 'proc/null_lL_WG33/Gordon333_SeitzmanSubcortical.32k_fs_LR.dlabel.nii'\n",
    "\n",
    "ax0 = nib.load(sample_file).header.get_axis(0)\n",
    "ax1 = nib.load(sample_file).header.get_axis(1)\n",
    "\n",
    "# get network labels\n",
    "parcel_labels = nib.load(sample_file).header.get_axis(1).name\n",
    "network_labels = []\n",
    "for s in parcel_labels:\n",
    "    b = s.split('_')\n",
    "    if len(b)<2:\n",
    "        network_labels.append(b[0])\n",
    "    else:\n",
    "        network_labels.append(b[1])\n",
    "network_labels = np.array(network_labels)\n",
    "network_names, network_sizes = np.unique(network_labels, return_counts=True)\n",
    "\n",
    "# load subject info\n",
    "subinfo = pd.read_csv(project_dir + 'proc/group/datasets/firstleveldatalabels_withpub_thresh0.8_20220412.csv', index_col=0)\n",
    "data = np.load(project_dir + 'proc/group/datasets/firstleveldata_thresh0.8_20220412.npy')\n",
    "subinfo.index.name='sub'\n",
    "\n",
    "scaredsr = pd.read_csv(os.path.join(project_dir, 'phenotypic_data','9994_SCARED_SR_20210322.csv'), index_col='EID', skiprows=[1]).loc[:,'SCARED_SR_SC']\n",
    "scaredsr.index = ['sub-{0}'.format(a) for a in scaredsr.index]\n",
    "scaredsr.index.name = 'sub'\n",
    "\n",
    "scaredpr = pd.read_csv(os.path.join(project_dir, 'phenotypic_data','9994_SCARED_P_20210322.csv'), index_col='EID', skiprows=[1]).loc[:,'SCARED_P_SC']\n",
    "scaredpr.index = ['sub-{0}'.format(a) for a in scaredpr.index]\n",
    "scaredpr.index.name = 'sub'\n",
    "\n",
    "mfqsr = pd.read_csv(os.path.join(project_dir, 'phenotypic_data','9994_MFQ_SR_20210322.csv'), index_col='EID', skiprows=[1]).loc[:,'MFQ_SR_Total']\n",
    "mfqsr.index = ['sub-{0}'.format(a) for a in mfqsr.index]\n",
    "mfqsr.index.name = 'sub'\n",
    "\n",
    "mfqpr = pd.read_csv(os.path.join(project_dir, 'phenotypic_data','9994_MFQ_P_20210322.csv'), index_col='EID', skiprows=[1]).loc[:,'MFQ_P_Total']\n",
    "mfqpr.index = ['sub-{0}'.format(a) for a in mfqpr.index]\n",
    "mfqpr.index.name = 'sub'\n",
    "\n",
    "subinfo = subinfo.merge(mfqsr, how='left', left_index=True, right_index=True)\n",
    "subinfo = subinfo.merge(mfqpr, how='left', left_index=True, right_index=True)\n",
    "subinfo = subinfo.merge(scaredsr, how='left', left_index=True, right_index=True)\n",
    "subinfo = subinfo.merge(scaredpr, how='left', left_index=True, right_index=True)\n",
    "subinfo = subinfo.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383e838-8c29-40df-a7f6-44b13d2b1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign developmental groups\n",
    "subinfo['age_group'] = 'middle'\n",
    "subinfo.loc[(subinfo['age']<8),'age_group'] = 'youngest'\n",
    "subinfo.loc[(subinfo['age']>11), 'age_group'] = 'oldest'\n",
    "\n",
    "subinfo.loc[np.isfinite(subinfo['PPS_score']), 'pub_group'] = 'middle'\n",
    "subinfo.loc[(subinfo['PPS_score']<=5),'pub_group'] = 'pre'\n",
    "subinfo.loc[(subinfo['PPS_score']>5) & (subinfo['PPS_score']<=10),'pub_group'] = 'early'\n",
    "subinfo.loc[(subinfo['PPS_score']>=15), 'pub_group'] = 'late'\n",
    "\n",
    "train_labels = subinfo.loc[subinfo['site']=='rubic',:]\n",
    "train_data = data[subinfo['site']=='rubic', :]\n",
    "test_labels = subinfo.loc[subinfo['site']=='cbic',:]\n",
    "test_data = data[subinfo['site']=='cbic', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489300e-55ef-43d8-87c1-4667da5fef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df30fe-90a8-440d-8e94-f7de65b43f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73046274-fb01-41f8-9ccc-45049db0ff8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Set up analysis functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538225f-276d-42b4-8fb3-a462c95c2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_fit(model, X, Y, groups, cv):\n",
    "    \n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    results = cross_validate(model, X=X, y=Y, groups=groups, n_jobs=10,\n",
    "                       cv=cv, return_estimator=True, scoring=scoring)\n",
    "    Y_pred = cross_val_predict(model, X=X, y=Y, groups=groups, n_jobs=10, cv=cv)\n",
    "    train_scores = results['test_score']\n",
    "\n",
    "    for i, a in enumerate(results['estimator']):\n",
    "        c = np.expand_dims(a.coef_, axis=2)\n",
    "        if i==0:\n",
    "            weights = c\n",
    "        else:\n",
    "            weights = np.concatenate([weights, c], axis=2)\n",
    "    \n",
    "    estimators = results['estimator']\n",
    "    weights = np.absolute(weights)\n",
    "    mean_weights = np.mean(np.mean(weights, axis=2), axis=0, keepdims=True)\n",
    "    return(estimators, weights, mean_weights, Y_pred, train_scores)\n",
    "\n",
    "def cv_fit_poly(model, X, Y, groups, cv):\n",
    "    \n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "        \n",
    "    results = cross_validate(model, X=X, y=Y, groups=groups, n_jobs=10,\n",
    "                       cv=cv, return_estimator=True, scoring=scoring)\n",
    "    Y_pred = cross_val_predict(model, X=X, y=Y, groups=groups, n_jobs=10, cv=cv)\n",
    "    train_scores = results['test_score']\n",
    "    estimators = results['estimator']\n",
    "    return(estimators, Y_pred, train_scores)\n",
    "\n",
    "\n",
    "def bootstrap_train_score(model, X, Y, groups, cv, outdir, kind='classifier', ci=90, samples=10000):\n",
    "    \n",
    "    # determine percentiles for the CI estimation from the bootstrapped distribution\n",
    "    lower = (100 - ci)/2\n",
    "    upper = 100 - lower\n",
    "\n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "\n",
    "    train_scores = []\n",
    "    corrcoeffs = []\n",
    "\n",
    "    for a in range(0,samples):\n",
    "        bootsample_size = random.randint(int(len(Y)*0.5),int(len(Y)*0.75))\n",
    "        subsampmask = np.full(len(Y), 0)\n",
    "        subsampmask[:bootsample_size] = 1\n",
    "        np.random.shuffle(subsampmask)\n",
    "        X_temp = X[subsampmask==1,:]\n",
    "        Y_temp = Y[subsampmask==1]\n",
    "        g_temp = groups[subsampmask==1]\n",
    "        results = cross_validate(model, X=X_temp, y=Y_temp, groups=g_temp, n_jobs=10,\n",
    "                                 cv=cv, return_estimator=False, scoring=scoring)\n",
    "        train_scores.append(results['test_score'])\n",
    "\n",
    "        if kind=='regress':\n",
    "            Y_t = cross_val_predict(model, X=X_temp, y=Y_temp, groups=g_temp, n_jobs=10, cv=cv)\n",
    "            r, p = scp.spearmanr(Y_temp, Y_t)\n",
    "            corrcoeffs.append(r)\n",
    "\n",
    "    # test if boot strapped distibution is normally distributed\n",
    "    train_scores = np.concatenate(train_scores).flatten()\n",
    "    k , p = scp.kstest(train_scores, 'norm')        \n",
    "\n",
    "    # store and save results\n",
    "    results = pd.DataFrame(columns = ['boot_mean','boot_SD','boot_median','KSstat','KSpval','CI','lowerCI','upperCI'])\n",
    "    results.loc['train_scores','boot_mean'] = np.mean(train_scores)\n",
    "    results.loc['train_scores','boot_SD'] = np.std(train_scores)\n",
    "    results.loc['train_scores','boot_median'] = np.percentile(train_scores, 50)\n",
    "    results.loc['train_scores','CI'] = ci\n",
    "    results.loc['train_scores','lowerCI'] = np.percentile(train_scores, lower)\n",
    "    results.loc['train_scores','upperCI'] = np.percentile(train_scores, upper)\n",
    "    results.loc['train_scores','KSstat'] = k\n",
    "    results.loc['train_scores','KSpval'] = p\n",
    "\n",
    "    if kind=='regress':\n",
    "        k , p = scp.kstest(corrcoeffs, 'norm')\n",
    "        corrcoeffs = np.array(corrcoeffs)\n",
    "\n",
    "        results.loc['pearsonr','boot_mean'] = np.mean(corrcoeffs)\n",
    "        results.loc['pearsonr','boot_SD'] = np.std(corrcoeffs)\n",
    "        results.loc['pearsonr','boot_median'] = np.percentile(corrcoeffs, 50)\n",
    "        results.loc['pearsonr','CI'] = ci\n",
    "        results.loc['pearsonr','lowerCI'] = np.percentile(corrcoeffs, lower)\n",
    "        results.loc['pearsonr','upperCI'] = np.percentile(corrcoeffs, upper)\n",
    "        results.loc['pearsonr','KSstat'] = k\n",
    "        results.loc['pearsonr','KSpval'] = p\n",
    "\n",
    "    results.to_csv(os.path.join(outdir, 'bootstrapped_training_accuracy_randN.csv'))\n",
    "\n",
    "    return(results)\n",
    "\n",
    "\n",
    "def predict_out(X, Y, estimators, kind):\n",
    "    index = range(0,len(Y))\n",
    "    for i, a in enumerate(estimators):\n",
    "        if i==0:\n",
    "            Y_pred = a.predict(X)\n",
    "            Y_test = Y\n",
    "            ind = index\n",
    "        else:\n",
    "            Y_pred = np.concatenate([Y_pred, a.predict(X)], axis=0)\n",
    "            Y_test = np.concatenate([Y_test, Y], axis=0)\n",
    "            ind = np.concatenate([ind, index], axis=0)\n",
    "\n",
    "    if kind=='classifier':\n",
    "        accuracy = pd.DataFrame.from_dict(classification_report(Y_test, Y_pred, output_dict=True)).T\n",
    "    elif kind=='regress':\n",
    "        var_series = pd.Series(Y_pred, index=ind)\n",
    "        var_series = var_series.groupby(var_series.index).mean()\n",
    "        accuracy = pd.DataFrame(columns = ['stat','pval'])\n",
    "        Y_test = Y\n",
    "        Y_pred = var_series.to_numpy()\n",
    "        accuracy.loc['SpearmanR','stat'], accuracy.loc['SpearmanR','pval'] = scp.spearmanr(Y_pred, Y_test)\n",
    "        accuracy.loc['PearsonR','stat'], accuracy.loc['PearsonR','pval'] = scp.pearsonr(Y_pred, Y_test)\n",
    "        slope, intercept, r, p, se = scp.linregress(Y_pred, Y_test)\n",
    "        accuracy.loc['LinearB','stat'] = slope\n",
    "        accuracy.loc['LinearB','pval'] = p\n",
    "        accuracy.loc['MSE','stat'] = mean_squared_error(Y_pred, Y_test)\n",
    "    return(Y_pred, accuracy)\n",
    "\n",
    "\n",
    "def boot_predict(estimators, X, Y, outdir, kind='classifier', ci=95, samples=10000):\n",
    "    # determine percentiles for the CI estimation from the bootstrapped distribution\n",
    "    lower = (100 - ci)/2\n",
    "    upper = 100 - lower\n",
    "\n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "\n",
    "    test_scores = []\n",
    "    pearsonr = []\n",
    "    spearmanr = []\n",
    "\n",
    "    for a in range(0,samples):\n",
    "        bootsample_size = random.randint(int(len(Y)*0.5),int(len(Y)*0.75))\n",
    "        subsampmask = np.full(len(Y), 0)\n",
    "        subsampmask[:bootsample_size] = 1\n",
    "        np.random.shuffle(subsampmask)\n",
    "        X_temp = X[subsampmask==1,:]\n",
    "        Y_temp = Y[subsampmask==1]\n",
    "\n",
    "        for a in estimators:\n",
    "            Y_pred = a.predict(X_temp)\n",
    "            if kind=='classifier':\n",
    "                t = classification_report(Y_temp, Y_pred, output_dict=True)\n",
    "                test_scores.append(t['accuracy'])\n",
    "            elif kind=='regress':\n",
    "                mse = mean_squared_error(Y_temp, Y_pred)\n",
    "                r, p = scp.spearmanr(Y_temp, Y_pred)\n",
    "                test_scores.append(mse)\n",
    "                spearmanr.append(r)\n",
    "                r, p = scp.pearsonr(Y_temp, Y_pred)\n",
    "                pearsonr.append(r)\n",
    "\n",
    "    # test if boot strapped distibution is normally distributed\n",
    "    test_scores = np.array(test_scores)\n",
    "    k , p = scp.kstest(test_scores, 'norm')        \n",
    "\n",
    "    # store and save results\n",
    "    results = pd.DataFrame(columns = ['boot_mean','boot_SD','boot_median','KSstat','KSpval','CI','lowerCI','upperCI'])\n",
    "    results.loc['test_scores','boot_mean'] = np.mean(test_scores)\n",
    "    results.loc['test_scores','boot_SD'] = np.std(test_scores)\n",
    "    results.loc['test_scores','boot_median'] = np.percentile(test_scores, 50)\n",
    "    results.loc['test_scores','CI'] = ci\n",
    "    results.loc['test_scores','lowerCI'] = np.percentile(test_scores, lower)\n",
    "    results.loc['test_scores','upperCI'] = np.percentile(test_scores, upper)\n",
    "    results.loc['test_scores','KSstat'] = k\n",
    "    results.loc['test_scores','KSpval'] = p\n",
    "\n",
    "    if kind=='regress':\n",
    "        k , p = scp.kstest(spearmanr, 'norm')\n",
    "        spearmanr = np.array(spearmanr)\n",
    "\n",
    "        results.loc['spearmanr','boot_mean'] = np.mean(spearmanr)\n",
    "        results.loc['spearmanr','boot_SD'] = np.std(spearmanr)\n",
    "        results.loc['spearmanr','boot_median'] = np.percentile(spearmanr, 50)\n",
    "        results.loc['spearmanr','CI'] = ci\n",
    "        results.loc['spearmanr','lowerCI'] = np.percentile(spearmanr, lower)\n",
    "        results.loc['spearmanr','upperCI'] = np.percentile(spearmanr, upper)\n",
    "        results.loc['spearmanr','KSstat'] = k\n",
    "        results.loc['spearmanr','KSpval'] = p\n",
    "\n",
    "        k , p = scp.kstest(pearsonr, 'norm')\n",
    "        pearsonr = np.array(pearsonr)\n",
    "\n",
    "        results.loc['pearsonr','boot_mean'] = np.mean(pearsonr)\n",
    "        results.loc['pearsonr','boot_SD'] = np.std(pearsonr)\n",
    "        results.loc['pearsonr','boot_median'] = np.percentile(pearsonr, 50)\n",
    "        results.loc['pearsonr','CI'] = ci\n",
    "        results.loc['pearsonr','lowerCI'] = np.percentile(pearsonr, lower)\n",
    "        results.loc['pearsonr','upperCI'] = np.percentile(pearsonr, upper)\n",
    "        results.loc['pearsonr','KSstat'] = k\n",
    "        results.loc['pearsonr','KSpval'] = p\n",
    "\n",
    "    results.to_csv(os.path.join(outdir, 'bootstrapped_test_accuracy_randN.csv'))\n",
    "    return(results)\n",
    "\n",
    "\n",
    "def make_confusion_matrix(Y, Y_pred, folds, outfile_name):\n",
    "    if Y.shape[0] < Y_pred.shape[0]:\n",
    "        Y_orig = Y\n",
    "        for i in range(1, folds):\n",
    "            Y = np.concatenate([Y,Y_orig], axis=0)\n",
    "\n",
    "    if Y.shape[0] == Y_pred.shape[0]:\n",
    "        fig = ConfusionMatrixDisplay.from_predictions(Y, Y_pred)\n",
    "        plt.savefig('{0}_{1}.svg'.format(outfile_name, today))\n",
    "    else:\n",
    "        print(\"ERROR: length mismatch\")    \n",
    "\n",
    "def make_consistency_plot(Y, Y_pred, folds, outfile_name):\n",
    "    if Y.shape[0] < Y_pred.shape[0]:\n",
    "        Y_orig = Y\n",
    "        for i in range(1, folds):\n",
    "            Y = np.concatenate([Y,Y_orig], axis=0)\n",
    "            \n",
    "    if Y.shape[0] == Y_pred.shape[0]:\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.scatter(Y, Y_pred)\n",
    "        plt.xlabel('Actual')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('{0}_{1}.svg'.format(outfile_name, today))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"ERROR: length mismatch\")    \n",
    "        \n",
    "def make_cifti_weights(weights, mean_weights, sample_file, out_prefix):\n",
    "    if weights.ndim==3:\n",
    "        weights = np.mean(weights, axis=2)\n",
    "    \n",
    "    ax0 = nib.cifti2.cifti2_axes.SeriesAxis(0,1,weights.shape[0], unit='second')\n",
    "    ax1 = nib.load(sample_file).header.get_axis(1)\n",
    "    weights_img = nib.cifti2.cifti2.Cifti2Image(weights, (ax0, ax1))\n",
    "    nib.save( weights_img, '{0}_SVM_weights_{1}.ptseries.nii'.format(out_prefix,today))\n",
    "\n",
    "    ax0 = nib.load(sample_file).header.get_axis(0)\n",
    "    ax1 = nib.load(sample_file).header.get_axis(1)\n",
    "    weights_img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(np.mean(mean_weights, axis=0), axis=0), (ax0, ax1))\n",
    "    nib.save( weights_img, '{0}_SVC_weights_mean_{1}.pscalar.nii'.format(out_prefix, today))\n",
    "\n",
    "def create_mean_act_files(X_train, Y_train, X_test, Y_test, sample_file, weights, out_folder, kind):\n",
    "    ax0 = nib.load(sample_file).header.get_axis(0)\n",
    "    ax1 = nib.load(sample_file).header.get_axis(1)\n",
    "\n",
    "    if kind=='classifier':\n",
    "        weight_table = pd.DataFrame(index=ax1.name)\n",
    "        weight_table['mean_weight'] = np.squeeze(weights)\n",
    "        train_activation = pd.DataFrame(X_train, columns = ax1.name, index=[a+'_train' for a in Y_train])\n",
    "        test_activation = pd.DataFrame(X_test, columns = ax1.name, index=[a+'_test' for a in Y_test])\n",
    "        activation = pd.concat(train_activation, test_activation)\n",
    "        mean_act = activation.groupby(activation.index.name).mean()\n",
    "        weight_table[mean_act.index] = mean_act.T\n",
    "        weight_table.to_csv('{0}weights_activation_table_{1}.csv'.format(out_folder, today))\n",
    "        for a in mean_act.index:\n",
    "            img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(mean_act.loc[a,:], axis=0), (ax0, ax1))\n",
    "            nib.save(img, '{0}mean_activation_{1}_{2}.pscalar.nii'.format(out_folder, a, today))\n",
    "\n",
    "    elif kind=='regress':\n",
    "        pearson = np.zeros((1, ax1.name.shape[0]))\n",
    "        for a in range(0,pearson.shape[1]):\n",
    "            r, p = scp.stats.pearsonr(X_train[:,a],Y_train)\n",
    "            pearson[:,a] = r\n",
    "        img = nib.cifti2.cifti2.Cifti2Image(pearson, (ax0, ax1))\n",
    "        nib.save(img, '{0}activation_train_pearsonr_{1}.pscalar.nii'.format(out_folder, today))\n",
    "        pearson = np.zeros((1, ax1.name.shape[0]))\n",
    "        for a in range(0,pearson.shape[1]):\n",
    "            r, p = scp.stats.pearsonr(X_test[:,a],Y_test)\n",
    "            pearson[:,a] = r\n",
    "        img = nib.cifti2.cifti2.Cifti2Image(pearson, (ax0, ax1))\n",
    "        nib.save(img, '{0}activation_test_pearsonr_{1}.pscalar.nii'.format(out_folder, today))\n",
    "\n",
    "def permuted_p(model, X, Y, cv, groups, out_folder, train_score, test_score, n_perms=1000):\n",
    "\n",
    "    # Perform permutation testing to get a p-value\n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "\n",
    "        train_score, permutation_scores, pvalue = permutation_test_score(model, X, Y, scoring=scoring, \n",
    "                                                                         cv=cv, n_permutations=n_perms, n_jobs=10, groups=groups)\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "        if isinstance(Y, pd.Series):\n",
    "            Y = Y.to_numpy()\n",
    "\n",
    "        Y_shuff = Y\n",
    "        scores = np.zeros((n_perms, cv.n_splits))\n",
    "        for a in range(0,n_perms):\n",
    "            np.random.shuffle(Y_shuff)\n",
    "            res = cross_validate(model, X=X, y=Y_shuff, groups=groups, n_jobs=10, cv=cv, scoring=scoring)\n",
    "            scores[a,:] = res['test_score']\n",
    "\n",
    "        permutation_scores = scores.flatten()\n",
    "\n",
    "    # Save a figure of the permutation scores\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "    ax.hist(permutation_scores, 20, label='Permutation scores', density=True)\n",
    "    ax.axvline(train_score, ls='-', color='m', label='Train')\n",
    "    ax.axvline(test_score, ls='--', color='g', label='Test')\n",
    "    if isinstance(model, SVC):\n",
    "        ax.axvline(1. / len(Y_train.unique()), ls='--', color='k', label='Chance')   \n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{0}permutation_plot_{1}.svg'.format(out_folder, today), transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    # Save scores as a csv\n",
    "    results = pd.DataFrame()\n",
    "    results.loc['Train_Score','Stat'] = train_score\n",
    "    results.loc['Test_Score','Stat'] = test_score\n",
    "    results.loc['Train_Score','PermPval'] = (np.sum((permutation_scores>=train_score).astype(int)) + 1) / (n_perms*cv.n_splits + 1)\n",
    "    results.loc['Test_Score','PermPval'] = (np.sum((permutation_scores>=test_score).astype(int)) + 1) / (n_perms*cv.n_splits + 1)\n",
    "    results.to_csv('{0}permutation_stats.csv'.format(out_folder))\n",
    "    return(results, permutation_scores)\n",
    "\n",
    "def permuted_importance(estimators_list, X, Y, sample_file, out_folder):\n",
    "    results = []\n",
    "    if isinstance(estimators_list[0], SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(estimators_list[0], SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    for a in estimators_list:\n",
    "        r = permutation_importance(a, X, Y, scoring=scoring, n_repeats=100, n_jobs=10, random_state=42)\n",
    "        results.append(r)\n",
    "\n",
    "    for i, r in enumerate(results):\n",
    "        if i==0:\n",
    "            imp_scores = r['importances'].T\n",
    "        else:\n",
    "            imp_scores = np.concatenate([imp_scores, r['importances'].T], axis=0)\n",
    "    \n",
    "    # save CIFTI with mean importance scores\n",
    "    ax0 = nib.load(sample_file).header.get_axis(0)\n",
    "    ax1 = nib.load(sample_file).header.get_axis(1)\n",
    "    impciftidata = np.expand_dims(np.mean(imp_scores, axis=0), axis=0)\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(impciftidata, (ax0, ax1))\n",
    "    nib.save(img, '{0}mean_permuted_importance_scores_{1}.pscalar.nii'.format(out_folder, today))\n",
    "    \n",
    "    # save dataframe with all the scores\n",
    "    imp_score_table = pd.DataFrame(imp_scores.T, index=ax1.name)\n",
    "    imp_score_table.to_csv('{0}permuted_importance_scores_{1}.csv'.format(out_folder, today))\n",
    "    \n",
    "    # save dataframe with mean scores\n",
    "    imp_mean=np.mean(imp_scores, axis=0, keepdims=True)\n",
    "    imp_table = pd.DataFrame(index=ax1.name)\n",
    "    imp_table['mean_importance'] = np.squeeze(imp_mean)\n",
    "    imp_table.to_csv('{0}mean_importance_{1}.csv'.format(out_folder, today))\n",
    "\n",
    "    # plot importance scores\n",
    "    imp_table['region'] = imp_table.index\n",
    "    sorted_imp_table = imp_table.sort_values(by='mean_importance', axis=0, ascending=False)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.barplot(x='mean_importance', y='region', data=sorted_imp_table.iloc[:20,:], ci=None, color=\"#3B75AF\")\n",
    "    plt.xlabel('Change in {0}'.format(scoring))\n",
    "    plt.ylabel('')\n",
    "    plt.axvline(0, color='gray', clip_on=False)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{0}top20importance_{1}.svg'.format(out_folder, today))\n",
    "    \n",
    "def permuted_network_importance(model, X, Y, sample_file, out_folder, model_score, n_perms=500):\n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    # get network names and sizes\n",
    "    parcel_labels = nib.load(sample_file).header.get_axis(1).name\n",
    "    network_labels = []\n",
    "    for s in parcel_labels:\n",
    "        b = s.split('_')\n",
    "        if len(b)<=2:\n",
    "            network_labels.append('Subcortical')\n",
    "        else:\n",
    "            network_labels.append(b[1])\n",
    "    network_labels = np.array(network_labels)\n",
    "    network_names, network_sizes = np.unique(network_labels, return_counts=True)\n",
    "    \n",
    "    # set up permutations\n",
    "    np.save(out_folder + 'temp.npy', X)\n",
    "    rng = np.random.default_rng()\n",
    "    perm_net_imp = pd.DataFrame(index=network_names, columns=range(0,n_perms))\n",
    "    perm_netrand_imp = pd.DataFrame(index=network_names, columns=range(0,n_perms))\n",
    "    model_score = np.mean(model_score)\n",
    "\n",
    "    for i in range(0,n_perms):\n",
    "        for net in network_names:\n",
    "            # permute only the network-specific features\n",
    "            net_perm_X = np.load(out_folder + 'temp.npy')\n",
    "            netperm = net_perm_X[:,network_labels==net]\n",
    "            netperm = rng.permutation(rng.permutation(netperm, axis=0), axis=1)\n",
    "            net_perm_X[:,network_labels==net] = netperm\n",
    "            results = cross_validate(model, X=net_perm_X, y=Y, groups=groups, n_jobs=10, cv=cv, scoring=scoring)\n",
    "            perm_imp = model_score - np.mean(results['test_score'])\n",
    "            perm_net_imp.loc[net,i] = perm_imp\n",
    "\n",
    "        for n, count in enumerate(network_sizes):\n",
    "            mask = np.full(X.shape[1], 0)\n",
    "            mask[:count] = 1\n",
    "            np.random.shuffle(mask)\n",
    "            net_perm_X = np.load(out_folder + 'temp.npy')\n",
    "            net_perm_X[:,mask] = rng.permutation(rng.permutation(X[:,mask], axis=0), axis=1)\n",
    "            results = cross_validate(model, X=net_perm_X, y=Y, groups=groups, n_jobs=10, cv=cv, scoring=scoring)\n",
    "            perm_imp = model_score - np.mean(results['test_score'])\n",
    "            perm_netrand_imp.loc[network_names[n],i] = perm_imp\n",
    "\n",
    "    os.remove(out_folder + 'temp.npy')\n",
    "    imp_table = perm_net_imp.mean(axis=1).to_frame(name='mean_importance')\n",
    "    imp_table['network'] = imp_table.index\n",
    "    sorted_imp_table = imp_table.sort_values(by='mean_importance', axis=0, ascending=False)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.barplot(x='mean_importance', y='network', data=sorted_imp_table, ci=None, color=\"#3B75AF\")\n",
    "    plt.xlabel('Mean Change in {0}'.format(scoring))\n",
    "    plt.ylabel('')\n",
    "    plt.axvline(0, color='gray', clip_on=False)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{0}network_importance_{1}.svg'.format(out_folder, today))\n",
    "\n",
    "    imp_table = perm_netrand_imp.mean(axis=1).to_frame(name='mean_importance')\n",
    "    imp_table['random_network'] = imp_table.index\n",
    "    sorted_imp_table = imp_table.sort_values(by='mean_importance', axis=0, ascending=False)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.barplot(x='mean_importance', y='random_network', data=sorted_imp_table, ci=None, color=\"#3B75AF\")\n",
    "    plt.xlabel('Mean Change in {0}'.format(scoring))\n",
    "    plt.ylabel('')\n",
    "    plt.axvline(0, color='gray', clip_on=False)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{0}random_networksize_importance_{1}.svg'.format(out_folder, today))\n",
    "    return(perm_net_imp, perm_netrand_imp)\n",
    "    \n",
    "def permuted_N_networks_importance(model, X, Y, N, sample_file, out_folder, model_score, n_perms=500):\n",
    "    if isinstance(model, SVC):\n",
    "        scoring = 'accuracy'\n",
    "    elif isinstance(model, SVR):\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    # get network names and sizes\n",
    "    parcel_labels = nib.load(sample_file).header.get_axis(1).name\n",
    "    network_labels = []\n",
    "    for s in parcel_labels:\n",
    "        b = s.split('_')\n",
    "        if len(b)<=2:\n",
    "            network_labels.append('Subcortical')\n",
    "        else:\n",
    "            network_labels.append(b[1])\n",
    "    network_labels = np.array(network_labels)\n",
    "    network_names, network_sizes = np.unique(network_labels, return_counts=True)\n",
    "    \n",
    "    # set up permutations\n",
    "    np.save(out_folder + 'temp.npy', X)\n",
    "    rng = np.random.default_rng()\n",
    "    perm_net_imp = pd.DataFrame(columns=range(0,n_perms))\n",
    "    perm_netrand_imp = pd.DataFrame(columns=range(0,n_perms))\n",
    "    model_score = np.mean(model_score)\n",
    "    combs = itertools.combinations(network_names, N)\n",
    "\n",
    "    for nets in combs:\n",
    "        for i in range(0,n_perms):\n",
    "            # permute only the network-specific features\n",
    "            net_perm_X = pd.DataFrame(np.load(out_folder + 'temp.npy'), columns=network_labels)\n",
    "            netperm = net_perm_X.loc[:,nets]\n",
    "            netperm = rng.permutation(rng.permutation(netperm, axis=0), axis=1)\n",
    "            net_perm_X.loc[:,nets] = netperm\n",
    "            results = cross_validate(model, X=net_perm_X, y=Y, groups=groups, n_jobs=15, cv=cv, scoring=scoring)\n",
    "            perm_imp = model_score - np.mean(results['test_score'])\n",
    "            perm_net_imp.loc['{0}'.format(nets),i] = perm_imp\n",
    "\n",
    "            mask = np.full(X.shape[1], 0)\n",
    "            mask[:netperm.shape[1]] = 1\n",
    "            np.random.shuffle(mask)\n",
    "            net_perm_X = np.load(out_folder + 'temp.npy')\n",
    "            net_perm_X[:,mask] = rng.permutation(rng.permutation(X[:,mask], axis=0), axis=1)\n",
    "            results = cross_validate(model, X=net_perm_X, y=Y, groups=groups, n_jobs=15, cv=cv, scoring=scoring)\n",
    "            perm_imp = model_score - np.mean(results['test_score'])\n",
    "            perm_netrand_imp.loc['{0}'.format(nets),i] = perm_imp\n",
    "\n",
    "    os.remove(out_folder + 'temp.npy')\n",
    "    \n",
    "    # Reorder the networks by mean permuted importance\n",
    "    imp_table = perm_net_imp.mean(axis=1).to_frame(name='mean_importance')\n",
    "    sorted_imp_table = imp_table.sort_values(by='mean_importance', axis=0, ascending=False)\n",
    "    neworder = sorted_imp_table.index\n",
    "\n",
    "    # reorder dataframes and drop to only top 20 means\n",
    "    perm_netrand_imp_reord = perm_netrand_imp.reindex(neworder).iloc[:20,:]\n",
    "    perm_net_imp_reord = perm_net_imp.reindex(neworder).iloc[:20,:]\n",
    "\n",
    "    # convert to long format\n",
    "    idvars = perm_netrand_imp_reord.columns\n",
    "    perm_netrand_imp_reord['networks'] = perm_netrand_imp_reord.index\n",
    "    temp_randperm = pd.melt(perm_netrand_imp_reord, id_vars=['networks'], value_vars=idvars, var_name='iter', value_name='perm_change_score')\n",
    "\n",
    "    idvars = perm_net_imp.columns\n",
    "    perm_net_imp_reord['networks'] = perm_net_imp_reord.index\n",
    "    temp_perm = pd.melt(perm_net_imp_reord, id_vars=['networks'], value_vars=idvars, var_name='iter', value_name='perm_change_score')\n",
    "\n",
    "    # Initialize figure\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    # Plot the actual permuted values\n",
    "    sns.boxenplot(x=\"perm_change_score\", y=\"networks\", data=temp_perm, \n",
    "                  color='#9370DB', showfliers=False)\n",
    "\n",
    "    # Plot the null distributions\n",
    "    sns.boxenplot(x=\"perm_change_score\", y=\"networks\", data=temp_randperm,\n",
    "                   color='darkgray', showfliers=False)\n",
    "\n",
    "    # Tweak the visual presentation and save\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.set(ylabel=\"\")\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{0}perm_N{1}_importance_{2}.svg'.format(out_folder, N, today))\n",
    "    \n",
    "    return(perm_net_imp, perm_netrand_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f20c51-ce63-4386-9766-51a1dd27bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make class to handle model fitting\n",
    "class permutedSVM:\n",
    "    def __init__(self, model, cv, output_folder, folds=10, perm_iters=1000):\n",
    "        self.cv = cv\n",
    "        self.folds = folds\n",
    "        self.perm_iters = perm_iters\n",
    "        self.outfolder = output_folder\n",
    "        self.random_state = model.random_state\n",
    "        self.parcel_labels = None\n",
    "        self.network_labels = None\n",
    "        self.groups = None\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "        self.bootstrap_train = None\n",
    "        self.X_test = None\n",
    "        self.Y_test = None\n",
    "        self.boostrap_test = None\n",
    "        self.model = model\n",
    "        self.estimators = None\n",
    "        self.weights = None\n",
    "        self.mean_weights = None\n",
    "        self.Y_test_pred = None\n",
    "        self.Y_train_pred = None\n",
    "        self.test_score = None\n",
    "        self.template_outfile = None\n",
    "        self.perm_pval = None\n",
    "        self.perm_scores = None\n",
    "        self.train_scores = None\n",
    "        self.net_perms = None\n",
    "        self.net_null_perms = None\n",
    "        self.N_net_perms = None\n",
    "        self.N_net_null_perms = None\n",
    "        \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    def fit(self, X_train, Y_train, groups, kernel='linear'):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.groups = groups \n",
    "        if kernel=='linear':\n",
    "            estimators, weights, mean_weights, Y_pred, train_scores = cv_fit(self.model, self.X_train, self.Y_train, self.groups, self.cv)\n",
    "            self.estimators = estimators\n",
    "            self.weights = weights\n",
    "            self.mean_weights = mean_weights\n",
    "            self.Y_train_pred = Y_pred\n",
    "            self.train_scores = train_scores\n",
    "        elif kernel=='poly':\n",
    "            estimators, Y_pred, train_scores = cv_fit_poly(self.model, self.X_train, self.Y_train, self.groups, self.cv)\n",
    "            self.estimators = estimators\n",
    "            self.Y_train_pred = Y_pred\n",
    "            self.train_scores = train_scores\n",
    "            \n",
    "        with open(os.path.join(self.outfolder,'insample_accuracy.txt'), 'w') as f:\n",
    "            f.write(str(np.mean(self.train_scores)))\n",
    "        return(self)\n",
    "    \n",
    "    def boot_fit(self, kind='classifier', ci=90, boot_samples=10000):\n",
    "        results = bootstrap_train_score(self.model, self.X_train, self.Y_train, self.groups, self.cv, self.outfolder, \n",
    "                                        kind=kind, ci=ci, samples=boot_samples)\n",
    "        self.bootstrap_train = results\n",
    "        return(self)\n",
    "    \n",
    "    def predict(self, X_test, Y_test, kind='classifier'):\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        Y_pred, accuracy = predict_out(self.X_test, self.Y_test, self.estimators, kind=kind)\n",
    "        self.Y_test_pred = Y_pred\n",
    "        self.test_score = accuracy\n",
    "        accuracy.to_csv(self.outfolder + 'performance_report.csv')\n",
    "        return(self)\n",
    "    \n",
    "    def boot_predict(self, kind='classifier', ci=90, boot_samples=10000):\n",
    "        results = boot_predict(self.estimators, self.X_test, self.Y_test, self.outfolder, kind=kind, ci=ci, samples=boot_samples)\n",
    "        self.bootstrap_test = results\n",
    "        return(self)\n",
    "\n",
    "    def plot_confusion(self, outfile_name='confusion_matrix'):\n",
    "        make_confusion_matrix(self.Y_test, self.Y_test_pred, self.folds, self.outfolder + outfile_name)\n",
    "    \n",
    "    def plot_consistency(self, outfile_name='consistency_plot'):\n",
    "        make_consistency_plot(self.Y_test, self.Y_test_pred, self.folds, self.outfolder + outfile_name)\n",
    "    \n",
    "    def plot_weights(self, template_outfile, out_prefix='model'):\n",
    "        self.template_outfile = template_outfile\n",
    "        make_cifti_weights(self.weights, self.mean_weights, self.template_outfile, self.outfolder + out_prefix)\n",
    "        \n",
    "    def make_weights_table_img(self, kind='classifier'):\n",
    "        create_mean_act_files(self.X_train, self.Y_train, self.X_test, self.Y_test, self.template_outfile, self.mean_weights, self.outfolder, kind)\n",
    "        \n",
    "    def calc_permuted_pvalue(self, kind='classifier'):\n",
    "        if kind=='classifier':\n",
    "            test_acc = self.test_score.loc['accuracy','precision']\n",
    "            train_acc = np.mean(self.train_scores)\n",
    "        elif kind=='regress':\n",
    "            test_acc = -svc.test_score.loc['MSE','stat']\n",
    "            train_acc = np.mean(self.train_scores)\n",
    "        pvalue, permutation_scores = permuted_p(self.model, self.X_train, self.Y_train, self.cv, self.groups, self.outfolder, train_acc, test_acc, n_perms=self.perm_iters)\n",
    "        self.perm_pval = pvalue\n",
    "        self.perm_scores = permutation_scores\n",
    "        np.save(self.outfolder + 'permutation_scores.npy', permutation_scores)\n",
    "        return(self)\n",
    "    \n",
    "    def get_perm_importance(self):\n",
    "        permuted_importance(self.estimators, self.X_train, self.Y_train, self.template_outfile, self.outfolder)\n",
    "        \n",
    "    def get_perm_net_importance(self, n_perms=500):\n",
    "        perm_net_imp, perm_netrand_imp = permuted_network_importance(self.model, self.X_train, self.Y_train, self.template_outfile, self.outfolder, self.train_scores, n_perms)\n",
    "        self.net_perms = perm_net_imp\n",
    "        perm_net_imp.to_csv(self.outfolder+'perm_N1_net_imp.csv')\n",
    "        self.net_null_perms = perm_netrand_imp\n",
    "        perm_netrand_imp.to_csv(self.outfolder+'perm_N1_randnet_imp.csv')\n",
    "        return(self)\n",
    "        \n",
    "    def get_perm_N_net_importance(self, N, n_perms=500):\n",
    "        perm_net_imp, perm_netrand_imp = permuted_N_networks_importance(self.model, self.X_train, self.Y_train, N, self.template_outfile, self.outfolder, self.train_scores, n_perms)\n",
    "        self.N_net_perms = perm_net_imp\n",
    "        perm_net_imp.to_csv(self.outfolder+'perm_N{0}_net_imp.csv'.format(N))\n",
    "        self.N_net_null_perms = perm_netrand_imp\n",
    "        perm_netrand_imp.to_csv(self.outfolder+'perm_N{0}_randnet_imp.csv'.format(N))\n",
    "        return(self)\n",
    "    \n",
    "    \n",
    "    def full_pipeline(self, X_train, Y_train, groups, X_test, Y_test, template_outfile, kernel='linear', kind='classifier'):\n",
    "        self.groups = groups\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.template_outfile = template_outfile\n",
    "\n",
    "        self.fit(X_train, Y_train, groups, kernel=kernel)\n",
    "        self.predict(X_test, Y_test, kind=kind)\n",
    "        self.plot_consistency()\n",
    "        self.boot_fit(kind=kind, ci=95)\n",
    "        self.boot_predict(kind=kind, ci=95)\n",
    "        self.make_weights_table_img(kind=kind)\n",
    "        self.calc_permuted_pvalue(kind='regress')\n",
    "        self.get_perm_importance()\n",
    "        self.get_perm_net_importance(n_perms=1000)\n",
    "        return(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b234457-64dd-403d-9700-b86985468d22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Run models: Is there a linear association between social anxiety and activation to emotional content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85c36c-a96e-4559-9612-87845e3160a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "cv = GroupKFold(n_splits=folds)\n",
    "random_state = 42\n",
    "model = SVR(kernel='linear')\n",
    "\n",
    "out_dir = os.path.join(clin_dir, 'SVM_linear')\n",
    "os.makedirs(out_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94debeb3-78ce-45cf-a6cf-cd685a5f4286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for clin in ['SCARED_P_SC', 'SCARED_SR_SC']:\n",
    "    if 'SR' in clin:\n",
    "        other = 'MFQ_SR_Total'\n",
    "    else:\n",
    "        other = 'MFQ_P_Total'\n",
    "\n",
    "    for emo in ['negative','anger','fear','loudness','brightness']:\n",
    "        print(emo, clin)\n",
    "        # subset training and testing data\n",
    "        X_train = train_data[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo)]\n",
    "        Y_train = train_labels[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo)]\n",
    "        groups = train_labels['sub'][np.isfinite(train_labels[clin]) & (train_labels['cond']==emo)]\n",
    "        X_test = test_data[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo)]\n",
    "        Y_test = test_labels[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo)]\n",
    "        out_folder = os.path.join(out_dir,'both_movies', emo, clin) + '/'\n",
    "\n",
    "        # regress out covariates from labels\n",
    "        Y_train.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_train.loc[:,['age', 'meanFD', clin, other]])\n",
    "        Y_train.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "        IterativeImputer(random_state=42).fit_transform(Y_train.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "        res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_train).fit()\n",
    "        Y_train = res.resid.to_frame().iloc[:,0]\n",
    "        \n",
    "        Y_test.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_test.loc[:,['age', 'meanFD', clin, other]])\n",
    "        Y_test.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "        IterativeImputer(random_state=42).fit_transform(Y_test.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "        res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_test).fit()\n",
    "        Y_test = res.resid.to_frame().iloc[:,0]\n",
    "\n",
    "        # run models\n",
    "        svc = permutedSVM(model=model, cv=cv, output_folder=out_folder)\n",
    "        svc = svc.fit(X_train, Y_train, groups)\n",
    "        svc = svc.predict(X_test, Y_test, kind='regress')\n",
    "        svc.plot_weights(sample_file)\n",
    "        svc.plot_consistency()\n",
    "        plt.close()\n",
    "        if (svc.test_score.loc['SpearmanR','pval']<0.05) & (svc.test_score.loc['SpearmanR','stat']>0):\n",
    "                svc.boot_predict(kind='regress')\n",
    "                if svc.bootstrap_test.loc['spearmanr','lowerCI']>0:\n",
    "                    svc.calc_permuted_pvalue(kind='regress')\n",
    "                    svc.get_perm_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d84c9b-789b-4c65-a6dc-cd1bc211f18c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mov in ['DM','TP']:\n",
    "    for clin in ['SCARED_P_SC', 'SCARED_SR_SC']:\n",
    "        if 'SR' in clin:\n",
    "            other = 'MFQ_SR_Total'\n",
    "        else:\n",
    "            other = 'MFQ_P_Total'\n",
    "\n",
    "        for emo in ['negative','anger','fear','loudness','brightness']:\n",
    "            print(emo, clin)\n",
    "            # subset training and testing data\n",
    "            X_train = train_data[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo) & (train_labels['movie']==mov)]\n",
    "            Y_train = train_labels[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo) & (train_labels['movie']==mov)]\n",
    "            groups = train_labels['sub'][np.isfinite(train_labels[clin]) & (train_labels['cond']==emo) & (train_labels['movie']==mov)]\n",
    "            X_test = test_data[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo) & (test_labels['movie']==mov)]\n",
    "            Y_test = test_labels[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo) & (test_labels['movie']==mov)]\n",
    "            out_folder = os.path.join(out_dir,'movie{0}'.format(mov), emo, clin) + '/'\n",
    "\n",
    "            # regress out covariates from labels\n",
    "            Y_train.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_train.loc[:,['age', 'meanFD', clin, other]])\n",
    "            Y_train.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "            IterativeImputer(random_state=42).fit_transform(Y_train.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "            res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_train).fit()\n",
    "            Y_train = res.resid.to_frame().iloc[:,0]\n",
    "\n",
    "            Y_test.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_test.loc[:,['age', 'meanFD', clin, other]])\n",
    "            Y_test.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "            IterativeImputer(random_state=42).fit_transform(Y_test.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "            res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_test).fit()\n",
    "            Y_test = res.resid.to_frame().iloc[:,0]\n",
    "\n",
    "            # run models\n",
    "            svc = permutedSVM(model=model, cv=cv, output_folder=out_folder)\n",
    "            svc = svc.fit(X_train, Y_train, groups)\n",
    "            svc = svc.predict(X_test, Y_test, kind='regress')\n",
    "            svc.template_outfile = sample_file\n",
    "            svc.plot_consistency()\n",
    "            plt.close()\n",
    "            if (svc.test_score.loc['SpearmanR','pval']<0.05) & (svc.test_score.loc['SpearmanR','stat']>0):\n",
    "                svc.boot_predict(kind='regress')\n",
    "                if svc.bootstrap_test.loc['spearmanr','lowerCI']>0:\n",
    "                    svc.calc_permuted_pvalue(kind='regress')\n",
    "                    svc.get_perm_importance()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fc4e0-f8df-4cb8-89a5-b135590415cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Is there a curvilinear association between social anxiety and activation to emotional content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405aba4-98a4-4ccc-ab32-72fe97dfb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "cv = GroupKFold(n_splits=folds)\n",
    "random_state = 42\n",
    "model = SVR(kernel='rbf')\n",
    "\n",
    "out_dir = os.path.join(clin_dir, 'SVM_curvilinear')\n",
    "os.makedirs(out_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99adb1-b5ed-4318-8209-cee78a599d57",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for clin in ['SCARED_P_SC', 'SCARED_SR_SC']:\n",
    "    if 'SR' in clin:\n",
    "        other = 'MFQ_SR_Total'\n",
    "    else:\n",
    "        other = 'MFQ_P_Total'\n",
    "\n",
    "    for emo in ['negative','anger','fear','loudness','brightness']:\n",
    "        print(emo, clin)\n",
    "        # subset training and testing data\n",
    "        X_train = train_data[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo)]\n",
    "        Y_train = train_labels[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo)]\n",
    "        groups = train_labels['sub'][np.isfinite(train_labels[clin]) & (train_labels['cond']==emo)]\n",
    "        X_test = test_data[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo)]\n",
    "        Y_test = test_labels[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo)]\n",
    "        out_folder = os.path.join(out_dir,'both_movies', emo, clin) + '/'\n",
    "\n",
    "        # regress out covariates from labels\n",
    "        Y_train.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_train.loc[:,['age', 'meanFD', clin, other]])\n",
    "        Y_train.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "        IterativeImputer(random_state=42).fit_transform(Y_train.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "        res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_train).fit()\n",
    "        Y_train = res.resid.to_frame().iloc[:,0]\n",
    "        \n",
    "        Y_test.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_test.loc[:,['age', 'meanFD', clin, other]])\n",
    "        Y_test.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "        IterativeImputer(random_state=42).fit_transform(Y_test.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "        res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_test).fit()\n",
    "        Y_test = res.resid.to_frame().iloc[:,0]\n",
    "\n",
    "        # run models\n",
    "        svc = permutedSVM(model=model, cv=cv, output_folder=out_folder)\n",
    "        svc = svc.fit(X_train, Y_train, groups, kernel='poly')\n",
    "        svc = svc.predict(X_test, Y_test, kind='regress')\n",
    "        svc.template_outfile = sample_file\n",
    "        if (svc.test_score.loc['SpearmanR','pval']<0.05) & (svc.test_score.loc['SpearmanR','stat']>0):\n",
    "                svc.boot_predict(kind='regress')\n",
    "                if svc.bootstrap_test.loc['spearmanr','lowerCI']>0:\n",
    "                    svc.calc_permuted_pvalue(kind='regress')\n",
    "                    svc.get_perm_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9be33-0f6d-4048-a1c3-29fab72a4033",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mov in ['DM','TP']:\n",
    "    for clin in ['SCARED_P_SC', 'SCARED_SR_SC']:\n",
    "        if 'SR' in clin:\n",
    "            other = 'MFQ_SR_Total'\n",
    "        else:\n",
    "            other = 'MFQ_P_Total'\n",
    "\n",
    "        for emo in ['negative','anger','fear','loudness','brightness']:\n",
    "            print(emo, clin)\n",
    "            # subset training and testing data\n",
    "            X_train = train_data[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo) & (train_labels['movie']==mov)]\n",
    "            Y_train = train_labels[np.isfinite(train_labels[clin]) & (train_labels['cond']==emo) & (train_labels['movie']==mov)]\n",
    "            groups = train_labels['sub'][np.isfinite(train_labels[clin]) & (train_labels['cond']==emo) & (train_labels['movie']==mov)]\n",
    "            X_test = test_data[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo) & (test_labels['movie']==mov)]\n",
    "            Y_test = test_labels[np.isfinite(test_labels[clin]) & (test_labels['cond']==emo) & (test_labels['movie']==mov)]\n",
    "            out_folder = os.path.join(out_dir,'movie{0}'.format(mov), emo, clin) + '/'\n",
    "\n",
    "            # regress out covariates from labels\n",
    "            Y_train.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_train.loc[:,['age', 'meanFD', clin, other]])\n",
    "            Y_train.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "            IterativeImputer(random_state=42).fit_transform(Y_train.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "            res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_train).fit()\n",
    "            Y_train = res.resid.to_frame().iloc[:,0]\n",
    "\n",
    "            Y_test.loc[:,['age','meanFD', clin, other]] = StandardScaler().fit_transform(Y_test.loc[:,['age', 'meanFD', clin, other]])\n",
    "            Y_test.loc[:,['age', 'female', 'meanFD', clin, other]] = \\\n",
    "            IterativeImputer(random_state=42).fit_transform(Y_test.loc[:,['age', 'female', 'meanFD', clin, other]])\n",
    "            res = smf.ols('{0} ~ age + female + meanFD + {1}'.format(clin, other), data=Y_test).fit()\n",
    "            Y_test = res.resid.to_frame().iloc[:,0]\n",
    "\n",
    "            # run models\n",
    "            svc = permutedSVM(model=model, cv=cv, output_folder=out_folder)\n",
    "            svc = svc.fit(X_train, Y_train, groups, kernel='poly')\n",
    "            svc = svc.predict(X_test, Y_test, kind='regress')\n",
    "            svc.template_outfile = sample_file\n",
    "            svc.plot_consistency()\n",
    "            plt.close()\n",
    "            if (svc.test_score.loc['SpearmanR','pval']<0.05) & (svc.test_score.loc['SpearmanR','stat']>0):\n",
    "                svc.boot_predict(kind='regress')\n",
    "                if svc.bootstrap_test.loc['spearmanr','lowerCI']>0:\n",
    "                    svc.calc_permuted_pvalue(kind='regress')\n",
    "                    svc.get_perm_importance()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece354fe-a943-4026-8954-446f213dde1c",
   "metadata": {},
   "source": [
    "# Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a943e9-4a0a-4d6f-8261-a2f703e1166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['clin','activation','spearmanr','spearmanCI','spearmanp','pearsonr','pearsonCI','pearsonp','MSE'])\n",
    "\n",
    "out_dir = os.path.join(clin_dir, 'SVM_curvilinear')\n",
    "idx = 0\n",
    "for clin in ['SCARED_P_SC', 'SCARED_SR_SC']:\n",
    "    for emo in ['negative','anger','fear','loudness','brightness']:\n",
    "        results.loc[idx, 'clin'] = clin\n",
    "        results.loc[idx, 'activation'] = emo\n",
    "        boot  = pd.read_csv(os.path.join(out_dir,'both_movies', emo, clin, 'bootstrapped_test_accuracy_randN.csv'), index_col = 0)\n",
    "        results.loc[idx, 'spearmanr'] = boot.loc['spearmanr','boot_mean']\n",
    "        results.loc[idx, 'spearmanCI'] = '[{0}, {1}]'.format(round(boot.loc['spearmanr','lowerCI'],2), round(boot.loc['spearmanr','upperCI'],2))\n",
    "        results.loc[idx, 'pearsonr'] = boot.loc['pearsonr','boot_mean']\n",
    "        results.loc[idx, 'pearsonCI'] = '[{0}, {1}]'.format(round(boot.loc['pearsonr','lowerCI'],2), round(boot.loc['pearsonr','upperCI'],2))\n",
    "        res = pd.read_csv(os.path.join(out_dir,'both_movies', emo, clin, 'performance_report.csv'), index_col = 0)\n",
    "        results.loc[idx, 'spearmanp'] = res.loc['SpearmanR','pval']\n",
    "        results.loc[idx, 'pearsonp'] = res.loc['PearsonR','pval']\n",
    "        results.loc[idx, 'MSE'] = res.loc['MSE','stat']\n",
    "        idx = idx + 1\n",
    "results.to_csv(os.path.join(out_dir,'both_movies','compiled_stats.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
